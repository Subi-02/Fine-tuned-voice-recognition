# Fine-tuned-voice-recognition


ğŸ“Œ Project Overview

This project implements an audio-only speech emotion recognition system that identifies human emotions from spoken audio signals using a fine-tuned pretrained deep learning model.

The system processes raw speech input and predicts emotional states such as neutral, happy, sad, angry, fearful, disgust, and surprise, based solely on audio characteristics.

ğŸ¯ Objective

To design and train a deep learning model capable of detecting emotions from speech audio by adapting a pretrained speech representation model through fine-tuning.

ğŸ§  Model Used
Wav2Vec2.0

Transformer-based speech representation model

Pretrained on large-scale unlabeled speech data

Fine-tuned for emotion classification using labeled emotional speech data

ğŸ›  Technologies & Libraries

Python

PyTorch

Hugging Face Transformers

Librosa

Torchaudio

NumPy

Scikit-learn

Google Colab (GPU)

ğŸ“‚ Dataset
RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)

Professional actor recordings

High-quality speech audio

8 emotion classes:

Neutral

Calm

Happy

Sad

Angry

Fearful

Disgust

Surprised

Dataset is downloaded and processed automatically within the project code.

ğŸ”„ Audio Processing Pipeline

Load .wav audio files

Resample audio to 16 kHz

Normalize audio amplitude

Extract speech representations using Wav2Vec2

Fine-tune classification layers

Predict emotion probabilities

âš™ï¸ Fine-Tuning Approach

Pretrained Wav2Vec2 encoder as feature extractor

Classification head trained on emotional speech labels

Cross-entropy loss function

AdamW optimizer

Low learning rate to prevent overfitting

ğŸ— Project Structure
Audio-Emotion-Detection/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset_download.py
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ audio_preprocessing.py
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ predict_emotion.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸš€ How to Run
Install Dependencies
pip install transformers datasets librosa torchaudio soundfile

Train the Model
python train_model.py

Predict Emotion
python predict_emotion.py --audio sample.wav

ğŸ“Š Sample Output
Predicted Emotion: Neutral

Emotion Probabilities:
Neutral   : 0.62
Happy     : 0.18
Sad       : 0.10
Angry     : 0.06
Fearful   : 0.04

ğŸ§ª Evaluation

Accuracy measurement

Emotion-wise probability analysis

Confusion matrix visualization

ğŸ’¡ Applications

Speech-based sentiment analysis

Call center monitoring

Voice-based interaction systems

Behavioral and emotional analysis

ğŸ”® Future Enhancements

Real-time microphone input

Multilingual emotion recognition

Noise-robust emotion detection

Deployment using REST APIs

Extension to video-based emotion recognition
